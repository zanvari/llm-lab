{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f0a183f2",
      "metadata": {
        "id": "f0a183f2"
      },
      "source": [
        "# üìò Fine-Tune DistilBERT on AG News\n",
        "This tutorial demonstrates how to fine-tune a pretrained DistilBERT model on the AG News dataset using HuggingFace's Transformers library. We go step-by-step: from installing dependencies and loading data, to training the model and evaluating results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e78d025c",
      "metadata": {
        "id": "e78d025c"
      },
      "source": [
        "# üß† Fine-Tune DistilBERT on AG News (Fixed Version)\n",
        "\n",
        "This notebook loads the AG News dataset via Kaggle, tokenizes it, fine-tunes a DistilBERT model, and evaluates the results with a confusion matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e5c568d",
      "metadata": {
        "id": "3e5c568d"
      },
      "source": [
        "## üì¶ Install Required Libraries\n",
        "Install HuggingFace Transformers, Datasets, Evaluate, Scikit-learn, and Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d761c78b",
      "metadata": {
        "id": "d761c78b"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -U transformers datasets evaluate scikit-learn kaggle --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "722cb2d2",
      "metadata": {
        "id": "722cb2d2"
      },
      "source": [
        "## üîê Upload Kaggle API Key\n",
        "Upload your `kaggle.json` file downloaded from your Kaggle account page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "992d3bc4",
      "metadata": {
        "id": "992d3bc4"
      },
      "outputs": [],
      "source": [
        "# Upload kaggle.json to authenticate\n",
        "from google.colab import files\n",
        "files.upload()  # Choose kaggle.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58251b6b",
      "metadata": {
        "id": "58251b6b"
      },
      "source": [
        "## üì• Download AG News from Kaggle\n",
        "Use the Kaggle CLI to download and unzip the dataset into the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11581d99",
      "metadata": {
        "id": "11581d99"
      },
      "outputs": [],
      "source": [
        "# Set up Kaggle API\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "162e7f49",
      "metadata": {
        "id": "162e7f49"
      },
      "source": [
        "## üßº Load and Preprocess the Dataset\n",
        "We read the CSVs, merge `title` and `description` fields, convert labels from 1‚Äì4 to 0‚Äì3, and clean the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe368da",
      "metadata": {
        "id": "afe368da"
      },
      "outputs": [],
      "source": [
        "# Download and unzip AG News dataset\n",
        "!kaggle datasets download -d amananandrai/ag-news-classification-dataset\n",
        "!unzip ag-news-classification-dataset.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4742ba0b",
      "metadata": {
        "id": "4742ba0b"
      },
      "source": [
        "## üî† Tokenize the Text\n",
        "Use `DistilBertTokenizerFast` to tokenize the `text` column with truncation and padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6f311b9",
      "metadata": {
        "id": "b6f311b9"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    DistilBertTokenizerFast,\n",
        "    DistilBertForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9106cbf7",
      "metadata": {
        "id": "9106cbf7"
      },
      "source": [
        "## ü§ñ Load the Pretrained Model\n",
        "Load a `DistilBertForSequenceClassification` model with 4 output labels for our classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a6ab2af",
      "metadata": {
        "id": "3a6ab2af"
      },
      "outputs": [],
      "source": [
        "# Load CSVs and skip the header row\n",
        "train_df = pd.read_csv(\"train.csv\", skiprows=1, header=None, names=[\"label\", \"title\", \"description\"])\n",
        "test_df = pd.read_csv(\"test.csv\", skiprows=1, header=None, names=[\"label\", \"title\", \"description\"])\n",
        "\n",
        "\n",
        "train_df[\"text\"] = train_df[\"title\"] + \" \" + train_df[\"description\"]\n",
        "test_df[\"text\"] = test_df[\"title\"] + \" \" + test_df[\"description\"]\n",
        "\n",
        "# üîß Convert 1‚Äì4 labels to 0‚Äì3\n",
        "train_df[\"label\"] = train_df[\"label\"].astype(int) - 1\n",
        "test_df[\"label\"] = test_df[\"label\"].astype(int) - 1\n",
        "\n",
        "# Drop unnecessary columns\n",
        "train_df = train_df[[\"label\", \"text\"]]\n",
        "test_df = test_df[[\"label\", \"text\"]]\n",
        "\n",
        "# Convert to HuggingFace Datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ce6fc67",
      "metadata": {
        "id": "3ce6fc67"
      },
      "source": [
        "## ‚öôÔ∏è Define Training Arguments\n",
        "Specify batch sizes, number of epochs, logging directory, and disable external logging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "797a1180",
      "metadata": {
        "id": "797a1180"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "encoded_dataset = dataset.map(tokenize, batched=True)\n",
        "encoded_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ed49ad4",
      "metadata": {
        "id": "4ed49ad4"
      },
      "source": [
        "## üìè Define Evaluation Metric\n",
        "We use HuggingFace's `evaluate` to calculate classification accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac687fbe",
      "metadata": {
        "id": "ac687fbe"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "455a9a84",
      "metadata": {
        "id": "455a9a84"
      },
      "source": [
        "## üöÄ Train the Model\n",
        "Initialize the `Trainer` and run the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1181358f",
      "metadata": {
        "id": "1181358f"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Fix: Use minimal compatible TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"  # disables W&B and others\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ff71224",
      "metadata": {
        "id": "7ff71224"
      },
      "source": [
        "## üìä Evaluate the Model\n",
        "Display the classification report and confusion matrix to understand model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37d308b3",
      "metadata": {
        "id": "37d308b3"
      },
      "outputs": [],
      "source": [
        "# Define metrics\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cbc4802",
      "metadata": {
        "id": "3cbc4802"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zvg5KeeQLHUs",
      "metadata": {
        "id": "zvg5KeeQLHUs"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"checkpoint-epoch-x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6qSZolIyBMrI",
      "metadata": {
        "id": "6qSZolIyBMrI"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"distilbert-agnews\", 'zip', \"distilbert-agnews-checkpoint\")\n",
        "files.download(\"distilbert-agnews.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "000eb218",
      "metadata": {
        "id": "000eb218"
      },
      "outputs": [],
      "source": [
        "# Evaluate and visualize\n",
        "predictions = trainer.predict(encoded_dataset[\"test\"])\n",
        "y_true = predictions.label_ids\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=[\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"World\", \"Sports\", \"Business\", \"Sci/Tech\"])\n",
        "disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix - DistilBERT on AG News\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}