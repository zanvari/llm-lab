# ðŸ“š Summarization Benchmarking

This project compares extractive and abstractive summarization methods using both traditional NLP and modern LLMs.

## ðŸ§ª Techniques
- **Extractive**: TextRank with spaCy + pytextrank
- **Abstractive**: FLAN-T5 via HuggingFace Transformers
- **Evaluation**: ROUGE metrics for output comparison

## ðŸ“˜ Notebook
- [`summarization_benchmark.ipynb`](./summarization_benchmark.ipynb)

## ðŸ“‚ Structure
```
summarization-benchmark/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_article.txt
â”œâ”€â”€ outputs/                     # Saved summaries or eval results
â”œâ”€â”€ summarization_benchmark.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ðŸ“¦ Requirements
Install with:
```bash
pip install -r requirements.txt
```

## âœ… Goal
Understand trade-offs between extractive vs. abstractive summarization for real-world documents.
