{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da942ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install langchain openai faiss-cpu tiktoken PyPDF2 chromadb sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS, Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import pipeline\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e7db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = PyPDFLoader(\"data/contract_detailed.pdf\")\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} pages from contract_detailed.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55727627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "all_docs = []\n",
    "data_path = Path(\"data\")\n",
    "for file in data_path.glob(\"*.pdf\"):\n",
    "    docs = PyPDFLoader(str(file)).load()\n",
    "    all_docs.extend(docs)\n",
    "print(f\"Loaded total {len(all_docs)} pages from {len(list(data_path.glob('*.pdf')))} PDFs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dfe9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(all_docs)\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afbbeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_oa = OpenAIEmbeddings()\n",
    "embedding_hf = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea561f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faiss_store = FAISS.from_documents(chunks, embedding_oa)\n",
    "chroma_store = Chroma.from_documents(chunks, embedding_hf, collection_name=\"rag-demo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faiss_retriever = faiss_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "mmr_retriever = chroma_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_oa = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "# Optional: HuggingFace\n",
    "# hf_pipe = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "# llm_hf = HuggingFacePipeline(pipeline=hf_pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a575db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa_openai_faiss = RetrievalQA.from_chain_type(llm=llm_oa, retriever=faiss_retriever, return_source_documents=True)\n",
    "qa_openai_mmr = RetrievalQA.from_chain_type(llm=llm_oa, retriever=mmr_retriever, return_source_documents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8782c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"What are the termination conditions in the contract?\"\n",
    "result_faiss = qa_openai_faiss({\"query\": query})\n",
    "result_mmr = qa_openai_mmr({\"query\": query})\n",
    "\n",
    "print(\"FAISS + OpenAI Answer:\\n\", result_faiss['result'])\n",
    "print(\"\\nSources:\")\n",
    "for doc in result_faiss['source_documents']:\n",
    "    print(\"-\", doc.metadata.get(\"source\", \"N/A\"))\n",
    "\n",
    "print(\"\\nMMR + OpenAI Answer:\\n\", result_mmr['result'])\n",
    "print(\"\\nSources:\")\n",
    "for doc in result_mmr['source_documents']:\n",
    "    print(\"-\", doc.metadata.get(\"source\", \"N/A\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0024f",
   "metadata": {},
   "source": [
    "\n",
    "## üîç Comparison Notes\n",
    "\n",
    "### Embeddings\n",
    "- **OpenAIEmbeddings**: High quality, token cost\n",
    "- **HuggingFaceEmbeddings**: Local, fast, free\n",
    "\n",
    "### Vector Stores\n",
    "- **FAISS**: Great for local/offline\n",
    "- **Chroma**: More flexible for MMR, metadata filtering\n",
    "\n",
    "### Retrievers\n",
    "- **Similarity**: Retrieves most relevant\n",
    "- **MMR**: Promotes diversity\n",
    "\n",
    "### Generators\n",
    "- **OpenAI Chat**: Very accurate\n",
    "- **HuggingFacePipeline**: Local model option\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faiss_store.save_local(\"vectorstore/faiss\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
