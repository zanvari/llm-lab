{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149c7cc2",
   "metadata": {},
   "source": [
    "# üß† BERT + Topic Modeling\n",
    "\n",
    "This notebook demonstrates how to cluster documents using BERT embeddings and extract meaningful topics using KeyBERT and HDBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc349c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import umap\n",
    "import hdbscan\n",
    "from keybert import KeyBERT\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c586fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/documents.json\") as f:\n",
    "    docs = json.load(f)\n",
    "\n",
    "texts = [doc[\"text\"] for doc in docs]\n",
    "print(f\"Loaded {len(texts)} documents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c7323",
   "metadata": {},
   "source": [
    "## üî¢ Sentence-BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(texts, convert_to_numpy=True, normalize_embeddings=True)\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ecead",
   "metadata": {},
   "source": [
    "## üîç HDBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=2, metric='euclidean')\n",
    "labels = clusterer.fit_predict(embeddings)\n",
    "\n",
    "print(\"Cluster labels:\", labels)\n",
    "print(\"Number of clusters (excluding noise):\", len(set(labels)) - (1 if -1 in labels else 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca15e2",
   "metadata": {},
   "source": [
    "## üìä UMAP Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91939e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_neighbors=5, min_dist=0.3, metric='cosine', random_state=42)\n",
    "embedding_2d = reducer.fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=embedding_2d[:,0], y=embedding_2d[:,1], hue=labels, palette=\"Set2\", s=80)\n",
    "plt.title(\"UMAP projection of clustered docs\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd63991",
   "metadata": {},
   "source": [
    "## üß† Topic Extraction with KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262cf9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT(model)\n",
    "\n",
    "cluster_to_docs = {}\n",
    "for text, label in zip(texts, labels):\n",
    "    if label == -1:\n",
    "        continue\n",
    "    cluster_to_docs.setdefault(label, []).append(text)\n",
    "\n",
    "for label, group in cluster_to_docs.items():\n",
    "    keywords = kw_model.extract_keywords(\" \".join(group), keyphrase_ngram_range=(1, 2), stop_words=\"english\", top_n=5)\n",
    "    print(f\"Cluster {label}: {[kw[0] for kw in keywords]}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
