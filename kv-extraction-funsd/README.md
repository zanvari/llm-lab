# ğŸ§¾ Key-Value Extraction with LayoutLM and Donut

This project demonstrates how to preprocess the FUNSD dataset and fine-tune or evaluate layout-aware models like LayoutLM and Donut for extracting key-value pairs from scanned forms.

## ğŸ“š Highlights

- âœ… Preprocessing for FUNSD annotations
- âœ… Normalized bounding boxes
- âœ… HuggingFace-compatible `Dataset` class
- âœ… Fine-tuning `LayoutLM` with `Trainer`
- âœ… Donut inference without OCR
- âœ… Inference + bounding box visualization

## ğŸ§ª Dataset

We use the [FUNSD dataset](https://guillaumejaume.github.io/FUNSD/), a benchmark for form understanding with:
- Text annotations
- Bounding boxes
- Entity labels (key, value, other)
- Links between key-value pairs

## ğŸ¤– Models

### ğŸ“ LayoutLM
- Token classification model that uses layout + text
- Fine-tuned using HuggingFace Trainer

### ğŸ© Donut
- OCR-free vision-to-sequence model
- Trained for document QA
- Inference using prompt: "What are the key fields and their values?"

## ğŸ› ï¸ Structure

```
kv-extraction-funsd/
â”œâ”€â”€ data_preprocessing.py
â”œâ”€â”€ layoutlm_dataset.py
â”œâ”€â”€ donut_infer.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ layoutlm_funsd.ipynb
â”‚   â””â”€â”€ donut_inference.ipynb
```

## ğŸ§ª Run

### LayoutLM
```bash
# Train LayoutLM with notebook or script
```

### Donut Inference
```bash
python donut_infer.py --image data/images/0000971160.png
```

## ğŸ”§ Setup

```bash
pip install -r requirements.txt
```
