# â“ BERT QA Fine-tuning â€” SQuAD

Fine-tune `bert-base-uncased` on the Stanford Question Answering Dataset (SQuAD v1.1) using HuggingFace Transformers.

---

## ğŸ“ Structure
- `notebooks/qa_finetune.ipynb` â€” Full notebook: training, evaluation, prediction
- `data/` â€” (Optional) store preprocessed or downloaded data
- `outputs/` â€” Saved fine-tuned model checkpoints

---

## âœ… Goals
- Load and tokenize SQuAD v1.1
- Train BERT for extractive QA
- Evaluate EM/F1 on the validation set
- Run inference on new questions + context

---

## ğŸ§ª Model
- `bert-base-uncased`
- Architecture: `BertForQuestionAnswering`

---

## ğŸ”§ Setup
```bash
pip install -r requirements.txt
```

---

## ğŸ“¦ Dependencies
- transformers
- datasets
- torch
- tqdm
- scikit-learn


---

## ğŸ“˜ Notebook
- [qa_finetune.ipynb](./notebooks/qa_finetune.ipynb) â€“ Full training + inference walkthrough  
- â–¶ï¸ [Open in Colab](https://colab.research.google.com/github/zanvari/llm-lab/blob/main/bert-qa-squad/notebooks/qa_finetune.ipynb)

---

## ğŸ§ª Batch Inference + Evaluation
Run predictions and evaluate performance on a batch of QA inputs:

```bash
python predict_batch.py
```

- ğŸ“„ Input: `data/batch_input.json` (list of question-context pairs)
- ğŸ“Š Output: Exact Match (EM), F1, average inference time
