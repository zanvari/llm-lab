{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c180426",
   "metadata": {},
   "source": [
    "# ðŸ§ª Prompt Engineering Playground\n",
    "\n",
    "Explore how different prompt strategies perform across various LLMs like OpenAI, Mistral, and LLaMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e14c8",
   "metadata": {},
   "source": [
    "## ðŸ“„ Load Prompt Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc9b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/prompts.json\") as f:\n",
    "    prompts = json.load(f)\n",
    "\n",
    "for p in prompts:\n",
    "    print(f\"ID: {p['id']}\\nType: {p['type']}\\nTask: {p['task']}\\nInput: {p['input']}\\n{'-'*50}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f965127c",
   "metadata": {},
   "source": [
    "## ðŸ¤– Simulate LLM Responses (Replace with real APIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_openai(prompt: str) -> str:\n",
    "    return f\"[OpenAI Response] {prompt[:50]}...\"\n",
    "\n",
    "def query_mistral(prompt: str) -> str:\n",
    "    return f\"[Mistral Response] {prompt[:50]}...\"\n",
    "\n",
    "def query_llama(prompt: str) -> str:\n",
    "    return f\"[LLaMA Response] {prompt[:50]}...\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d10bb47",
   "metadata": {},
   "source": [
    "## ðŸ§ª Compare Prompt Strategies Across Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ed77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for p in prompts:\n",
    "    full_prompt = f\"{p['task']}\\n{p['input']}\"\n",
    "    result = {\n",
    "        \"id\": p[\"id\"],\n",
    "        \"type\": p[\"type\"],\n",
    "        \"OpenAI\": query_openai(full_prompt),\n",
    "        \"Mistral\": query_mistral(full_prompt),\n",
    "        \"LLaMA\": query_llama(full_prompt),\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"\\nðŸ”¹ Prompt ID: {r['id']} ({r['type']})\")\n",
    "    print(f\"OpenAI: {r['OpenAI']}\")\n",
    "    print(f\"Mistral: {r['Mistral']}\")\n",
    "    print(f\"LLaMA: {r['LLaMA']}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
