{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30c1acf",
   "metadata": {},
   "source": [
    "# üè∑Ô∏è Fine-tuning BERT for Named Entity Recognition (NER)\n",
    "Using `bert-base-cased` on CoNLL-2003 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622b4c45",
   "metadata": {},
   "source": [
    "## üì¶ Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add1c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2755234",
   "metadata": {},
   "source": [
    "## üìö Load CoNLL-2003 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9057290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"conll2003\")\n",
    "dataset = dataset.rename_column(\"ner_tags\", \"labels\")\n",
    "label_list = dataset[\"train\"].features[\"labels\"].feature.names\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27384334",
   "metadata": {},
   "source": [
    "## üî¢ Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f45b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_and_align_labels(example):\n",
    "    tokenized_inputs = tokenizer(example[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "    label_ids = []\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            label_ids.append(example[\"labels\"][word_idx])\n",
    "        else:\n",
    "            label_ids.append(example[\"labels\"][word_idx] if True else -100)\n",
    "        previous_word_idx = word_idx\n",
    "    tokenized_inputs[\"labels\"] = label_ids\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b83f03",
   "metadata": {},
   "source": [
    "## üß† Load BERT Model for Token Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"bert-base-cased\", num_labels=len(label_list)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b42e7",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a977e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report, f1_score\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./outputs\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p_, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_predictions = [\n",
    "        [label_list[p_] for (p_, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return {\"f1\": f1_score(true_labels, true_predictions)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7f9edc",
   "metadata": {},
   "source": [
    "## üìä Evaluation on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b883eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "preds = np.argmax(predictions, axis=2)\n",
    "\n",
    "true_labels = [\n",
    "    [label_list[l] for (p_, l) in zip(pred, label) if l != -100]\n",
    "    for pred, label in zip(preds, labels)\n",
    "]\n",
    "true_preds = [\n",
    "    [label_list[p_] for (p_, l) in zip(pred, label) if l != -100]\n",
    "    for pred, label in zip(preds, labels)\n",
    "]\n",
    "\n",
    "print(classification_report(true_labels, true_preds))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
