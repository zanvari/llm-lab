{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111f705f",
   "metadata": {},
   "source": [
    "# üè• RAG for Healthcare Document QA\n",
    "\n",
    "This notebook demonstrates how to build a RAG pipeline to answer questions from healthcare-related documents such as insurance claims or patient summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d63a53",
   "metadata": {},
   "source": [
    "## üì¶ Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain openai faiss-cpu sentence-transformers pypdf python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1dbaf",
   "metadata": {},
   "source": [
    "## üîë Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d09c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5615f79f",
   "metadata": {},
   "source": [
    "## üìÑ Load and Split PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9bfa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"data/health_insurance_claim_detailed.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Loaded {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f368e14f",
   "metadata": {},
   "source": [
    "## üîç Embed and Store with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db = FAISS.from_documents(chunks, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42750259",
   "metadata": {},
   "source": [
    "## üß† Set Up Retriever and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee270327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9e2bcc",
   "metadata": {},
   "source": [
    "## ‚ùì Ask Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e3bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What amount was claimed by the patient?\"\n",
    "response = rag_chain.run(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5239e5",
   "metadata": {},
   "source": [
    "## ‚úÖ Try More Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8faa3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Who is the policyholder?\",\n",
    "    \"What is the diagnosis?\",\n",
    "    \"What treatment was administered?\",\n",
    "    \"When was the claim submitted?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\nQ: {q}\\nA: {rag_chain.run(q)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b1072",
   "metadata": {},
   "source": [
    "## üìå Summary\n",
    "- Loaded healthcare PDF\n",
    "- Embedded chunks using SentenceTransformer\n",
    "- Retrieved context with FAISS\n",
    "- Answered questions using GPT-3.5\n",
    "\n",
    "Ready to customize for other domains or LLMs!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
