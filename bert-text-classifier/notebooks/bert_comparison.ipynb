{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48bf1555",
   "metadata": {},
   "source": [
    "# üß† BERT Model Comparison for Text Classification\n",
    "Compare BERT, DistilBERT, and RoBERTa on sentiment classification (IMDb dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ca462",
   "metadata": {},
   "source": [
    "## üì¶ Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856dc067",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets scikit-learn torch seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2b0c4f",
   "metadata": {},
   "source": [
    "## üìö Load IMDb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea204d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('imdb').shuffle(seed=42)\n",
    "small_train = dataset['train'].select(range(1000))\n",
    "small_test = dataset['test'].select(range(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b749a",
   "metadata": {},
   "source": [
    "## üßπ Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def tokenize_dataset(tokenizer_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    def tokenize_fn(examples):\n",
    "        return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "    tokenized_train = small_train.map(tokenize_fn, batched=True)\n",
    "    tokenized_test = small_test.map(tokenize_fn, batched=True)\n",
    "    tokenized_train.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    tokenized_test.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    return tokenized_train, tokenized_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d159924",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Train and evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds)\n",
    "    }\n",
    "\n",
    "def train_and_evaluate(model_name):\n",
    "    print(f\"\\nüöÄ Training {model_name}\")\n",
    "    train_data, test_data = tokenize_dataset(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"{model_name}-output\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=64,\n",
    "        num_train_epochs=1,\n",
    "        logging_steps=10,\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=False\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=test_data,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    print(f\"üìä Eval metrics for {model_name}: {metrics}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    preds = trainer.predict(test_data)\n",
    "    pred_labels = np.argmax(preds.predictions, axis=1)\n",
    "    cm = confusion_matrix(preds.label_ids, pred_labels)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(preds.label_ids, pred_labels))\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix ‚Äî {model_name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e9168",
   "metadata": {},
   "source": [
    "## üîç Run All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e70504",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ['bert-base-uncased', 'distilbert-base-uncased', 'roberta-base']:\n",
    "    train_and_evaluate(model)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
